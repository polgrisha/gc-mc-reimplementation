{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb5fac0",
   "metadata": {},
   "source": [
    "## Домашняя работа 2\n",
    "\n",
    "### Поляков Григорий M05-115a\n",
    "\n",
    "В данной работе рассматривается графовый рекоммендательный алгоритм из статьи [Graph Convolutional Matrix Completion\n",
    "](https://arxiv.org/pdf/1706.02263v2.pdf)\n",
    "\n",
    "#### Краткое описание алгоритма\n",
    "\n",
    "Дана разреженная матрица оценок пользователями товараов размера $(N_u, N_v)$, где $N_u$ - количество пользователей, $N_v$ - количество товаров. Наблюдаемые оценки - числа {1, ..., r}, ненаблюдаемые отмечены нулем. Требуется по наблюдаемым значениям восстановаить ненаблюдаемыею\n",
    "\n",
    "#### Загрузим данные\n",
    "\n",
    "Для начала попробуем воспроизвести результаты статьи на датасете [MovieLens 100K](https://grouplens.org/datasets/movielens/100k/)\n",
    "\n",
    "#### Скачаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e0a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "from random import sample\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import BatchSampler, SequentialSampler\n",
    "\n",
    "url = 'https://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "request = urlopen(url)\n",
    "\n",
    "with ZipFile(BytesIO(request.read())) as zip_ref:\n",
    "    zip_ref.extractall('./')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baade4f0",
   "metadata": {},
   "source": [
    "#### Построим по данным матрицу смежности графа\n",
    "\n",
    "Оценки пользователями фильмов лежат в файле `u.data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9653d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  rating  timestamp\n",
       "0   196   242       3  881250949\n",
       "1   186   302       3  891717742\n",
       "2    22   377       1  878887116\n",
       "3   244    51       2  880606923\n",
       "4   166   346       1  886397596"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['user', 'item', 'rating', 'timestamp'], \n",
    "                   encoding = 'latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc31593",
   "metadata": {},
   "source": [
    "Информация о пользователях и фильмах в файлах `u.item` и `u.user`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63bb4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of films: 1682\n"
     ]
    }
   ],
   "source": [
    "movie_data = pd.read_csv('./ml-100k/u.item', sep=r'|', header=None, encoding = 'latin-1')\n",
    "user_data = pd.read_csv('./ml-100k/u.user', sep=r'|', header=None, encoding = 'latin-1')\n",
    "num_users = user_data.shape[0]\n",
    "num_items = movie_data.shape[0]\n",
    "\n",
    "print(f'Number of users: {num_users}')\n",
    "print(f'Number of films: {num_items}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b11a8b3",
   "metadata": {},
   "source": [
    "В данном датафрейме лежит список ребер рассматриваемого графа.\n",
    "Разделим его на трейн и валидацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5305268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges in train: 80000\n",
      "Number of edges in val: 20000\n"
     ]
    }
   ],
   "source": [
    "train, val = train_test_split(data[['user', 'item', 'rating']].values, test_size=0.2, random_state=42)\n",
    "train = torch.tensor(train, dtype=torch.long)\n",
    "val = torch.tensor(val, dtype=torch.long)\n",
    "print(f'Number of edges in train: {train.shape[0]}')\n",
    "print(f'Number of edges in val: {val.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e1200e",
   "metadata": {},
   "source": [
    "Составим по списку ребер 5 матриц смежности, где в $i$-й матрице элемент $(j, k)$ будет равен 1, если пользователь $j$ поставил фильму $k$ оценку $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dae7df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_adj_matrix(num_users, num_items, edges_list, num_classes=5):\n",
    "    adj_matrix = torch.zeros(num_users, num_items, dtype=torch.long)\n",
    "    adj_matrix[edges_list[:, 0]-1, edges_list[:, 1]-1] = edges_list[:, 2]\n",
    "    \n",
    "    adj_matrices_class = []\n",
    "    for cl in range(1, num_classes+1):\n",
    "        adj_matrix_class = torch.zeros(num_users, num_items)\n",
    "        adj_matrix_class[adj_matrix == cl] = 1\n",
    "        adj_matrices_class.append(adj_matrix_class)\n",
    "    return torch.stack(adj_matrices_class, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96555f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adj_matr = make_adj_matrix(num_users, num_items, train)\n",
    "val_adj_matr = make_adj_matrix(num_users, num_items, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f128e",
   "metadata": {},
   "source": [
    "#### Имплементируем основной алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45923ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessagePassing(torch.nn.Module):\n",
    "    def __init__(self, num_classes, embedding_dim, hidden_dim):\n",
    "        super(MessagePassing, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # применение линейного слоя для каждого типа рейтинга перед message passing (W_r)\n",
    "        self.rating_linear = torch.nn.Parameter(torch.Tensor(num_classes, embedding_dim, embedding_dim))\n",
    "        self.playlist_song_linear = torch.nn.Parameter(torch.Tensor(2, embedding_dim, hidden_dim))\n",
    "        torch.nn.init.normal_(self.rating_linear, std=0.1)\n",
    "        torch.nn.init.normal_(self.playlist_song_linear, std=0.1)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def normalize(self, mx):\n",
    "        # применение симметричной нормализации в зависимости от числа соседей перед message passing\n",
    "        rowsum = torch.sum(mx, 0)\n",
    "        r_inv = torch.pow(rowsum, -0.5)\n",
    "        r_inv[torch.isinf(r_inv)] = 0.\n",
    "        r_mat_inv = torch.diag(r_inv)\n",
    "        colsum = torch.sum(mx, 1)\n",
    "        c_inv = torch.pow(colsum, -0.5)\n",
    "        c_inv[torch.isinf(c_inv)] = 0.\n",
    "        c_mat_inv = torch.diag(c_inv)\n",
    "\n",
    "        output = torch.matmul(mx, r_mat_inv)\n",
    "        output = torch.matmul(c_mat_inv, mx)\n",
    "        return output\n",
    "    \n",
    "    def forward(self, playlist_embeddings, song_embeddings, playlists, songs, adj_matrices):\n",
    "        assert self.num_classes == adj_matrices.shape[0]\n",
    "        \n",
    "        all_playlist_embeddings = []\n",
    "        all_song_embeddings = []\n",
    "        for i in range(adj_matrices.shape[0]):\n",
    "            # для каждого типа рейтинга производим свой message passing\n",
    "            adj_matrix = adj_matrices[i]\n",
    "            norm = self.normalize(adj_matrix)\n",
    "            playlist_norms = norm[playlists]\n",
    "            song_norms = norm.T[songs]\n",
    "            \n",
    "            # преобразовываем эмбеддинг каждой ноды и складываем с нормализованными весами\n",
    "            new_playlist_embeddings = playlist_norms @ (song_embeddings @ self.rating_linear[i])\n",
    "            new_song_embeddings = song_norms @ (playlist_embeddings @ self.rating_linear[i])\n",
    "            \n",
    "            all_playlist_embeddings.append(new_playlist_embeddings)\n",
    "            all_song_embeddings.append(new_song_embeddings)\n",
    "        \n",
    "        # суммируем эмбеддинги для по всем классам\n",
    "        all_playlist_embeddings = torch.stack(all_playlist_embeddings, 0).sum(0)\n",
    "        all_song_embeddings = torch.stack(all_song_embeddings, 0).sum(0)\n",
    "        \n",
    "        # линейное преобразование эмбедддингов пользователей и товаров по одтельности\n",
    "        all_playlist_embeddings = self.relu(all_playlist_embeddings @ self.playlist_song_linear[0])\n",
    "        all_song_embeddings = self.relu(all_song_embeddings @ self.playlist_song_linear[0])\n",
    "\n",
    "        return all_playlist_embeddings, all_song_embeddings\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, num_classes, embedding_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # билинейное преобразование эмбеддингов пользователей и товаров в зависимости от класса\n",
    "        self.bilinear_operator = torch.nn.Parameter(torch.Tensor(self.num_classes,\n",
    "                                                                 self.embedding_dim,\n",
    "                                                                 self.embedding_dim))\n",
    "        torch.nn.init.normal_(self.bilinear_operator, std=0.1)\n",
    "        \n",
    "    def forward(self, playlist_features, song_features):\n",
    "        output = []\n",
    "        for i in range(self.num_classes):\n",
    "            output.append(playlist_features @ self.bilinear_operator[i] @ song_features.T)\n",
    "        return torch.stack(output, 0)\n",
    "\n",
    "    \n",
    "class GAE(torch.nn.Module):\n",
    "    def __init__(self, num_playlists, num_songs, num_classes,\n",
    "                 embedding_dim, hidden_dim, dropout=0.7):\n",
    "        super(GAE, self).__init__()\n",
    "        self.num_playlists = num_playlists\n",
    "        self.num_songs = num_songs\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # начальное приближение эмбеддингов нод пользователей и товаров\n",
    "        self.playlist_embeddings = torch.nn.Parameter(torch.Tensor(self.num_playlists, self.embedding_dim))\n",
    "        self.song_embeddings = torch.nn.Parameter(torch.Tensor(self.num_songs, self.embedding_dim))\n",
    "        torch.nn.init.normal_(self.playlist_embeddings, std=0.1)\n",
    "        torch.nn.init.normal_(self.song_embeddings, std=0.1)\n",
    "        \n",
    "        # энкодер и декодер\n",
    "        self.graph_conv = MessagePassing(num_classes, embedding_dim, hidden_dim)\n",
    "        self.decoder = Decoder(num_classes, hidden_dim)\n",
    "        self.softmax =  torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, playlists, songs, adj_matrix):\n",
    "        playlist_embeddings, song_embeddings = self.graph_conv(self.playlist_embeddings, self.song_embeddings,\n",
    "                                                               playlists, songs, adj_matrix)\n",
    "        scores = self.decoder(playlist_embeddings, song_embeddings)\n",
    "        scores = self.softmax(scores)\n",
    "        return scores\n",
    "    \n",
    "    def ratings_from_scores(self, scores):\n",
    "        ratings = (scores * torch.tensor(range(self.num_classes)).reshape(-1, 1, 1)).sum(0)\n",
    "        return ratings\n",
    "    \n",
    "    def predict(self, playlist):\n",
    "        playlist_emb = self.playlist_embeddings[playlist].unsqueeze(0)\n",
    "        scores = self.decoder(playlist_emb, self.song_embeddings)\n",
    "        scores = self.softmax(scores)\n",
    "        print(scores.shape)\n",
    "        return self.ratings_from_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8545e97",
   "metadata": {},
   "source": [
    "#### Лосс, метрики и пайплайн обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "324f2449",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(logits, labels):\n",
    "    omg = torch.sum(labels, 0).detach()\n",
    "    len_omg = len(torch.nonzero(omg))\n",
    "\n",
    "    pred_y = logits\n",
    "    y = torch.max(labels, 0)[1].float() + 1.\n",
    "\n",
    "    se = torch.sub(y, pred_y).pow_(2)\n",
    "    mse= torch.sum(torch.mul(omg, se))/len_omg\n",
    "    rmse = torch.sqrt(mse)\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def rmse()\n",
    "\n",
    "\n",
    "def loss(probs, target):\n",
    "    probs = probs.reshape(probs.shape[0], -1)\n",
    "    target = target.reshape(target.shape[0], -1)\n",
    "    target_class = target.max(dim=0)[1]\n",
    "    \n",
    "    return torch.nn.functional.cross_entropy(probs, target) / target.sum()\n",
    "\n",
    "\n",
    "def train(model, adj_matrix, num_playlists, num_songs, optim):\n",
    "    model.train()\n",
    "    optim.zero_grad()\n",
    "    output = model(torch.tensor(range(num_playlists)),\n",
    "                   torch.tensor(range(num_songs)),\n",
    "                   adj_matrix.clone())\n",
    "    curr_loss = loss(output, adj_matrix)\n",
    "    #################################################################################\n",
    "    m_hat = torch.stack([(r+1)*out for r, out in enumerate(output)], 0)\n",
    "    m_hat = torch.sum(m_hat, 0)\n",
    "    #################################################################################\n",
    "    print(curr_loss)\n",
    "    print(rmse(m_hat, adj_matrix))\n",
    "    curr_loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "def evaluate(model, adj_matrix, num_playlists, num_songs):\n",
    "    model.eval()\n",
    "    u = torch.tensor(range(num_playlists))\n",
    "    v = torch.tensor(range(num_songs))\n",
    "    \n",
    "    output = model(u, v, adj_matrix.clone())\n",
    "    m_hat = torch.stack([(r+1)*out for r, out in enumerate(output)], 0)\n",
    "    m_hat = torch.sum(m_hat, 0)\n",
    "    \n",
    "    print(rmse(m_hat, adj_matrix))\n",
    "    return m_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dd64d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce1de9522154a14bc1a8567965cba62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "tensor(2.8555, grad_fn=<DivBackward0>)\n",
      "tensor(1.2452, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2401, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8555, grad_fn=<DivBackward0>)\n",
      "tensor(1.2452, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2401, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8555, grad_fn=<DivBackward0>)\n",
      "tensor(1.2451, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2401, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8556, grad_fn=<DivBackward0>)\n",
      "tensor(1.2451, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2400, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8553, grad_fn=<DivBackward0>)\n",
      "tensor(1.2448, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2398, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8555, grad_fn=<DivBackward0>)\n",
      "tensor(1.2439, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2392, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8551, grad_fn=<DivBackward0>)\n",
      "tensor(1.2414, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2375, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8549, grad_fn=<DivBackward0>)\n",
      "tensor(1.2341, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2333, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8542, grad_fn=<DivBackward0>)\n",
      "tensor(1.2165, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2236, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8525, grad_fn=<DivBackward0>)\n",
      "tensor(1.1827, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.2040, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8496, grad_fn=<DivBackward0>)\n",
      "tensor(1.1371, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.1703, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8455, grad_fn=<DivBackward0>)\n",
      "tensor(1.1052, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.1286, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8423, grad_fn=<DivBackward0>)\n",
      "tensor(1.1120, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.1013, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8421, grad_fn=<DivBackward0>)\n",
      "tensor(1.1404, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0973, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8431, grad_fn=<DivBackward0>)\n",
      "tensor(1.1598, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0992, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8439, grad_fn=<DivBackward0>)\n",
      "tensor(1.1671, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0979, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8440, grad_fn=<DivBackward0>)\n",
      "tensor(1.1664, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0918, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8435, grad_fn=<DivBackward0>)\n",
      "tensor(1.1594, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0826, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8425, grad_fn=<DivBackward0>)\n",
      "tensor(1.1460, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0730, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8412, grad_fn=<DivBackward0>)\n",
      "tensor(1.1261, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0672, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8400, grad_fn=<DivBackward0>)\n",
      "tensor(1.1007, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0694, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8391, grad_fn=<DivBackward0>)\n",
      "tensor(1.0751, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0801, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8391, grad_fn=<DivBackward0>)\n",
      "tensor(1.0567, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0915, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8397, grad_fn=<DivBackward0>)\n",
      "tensor(1.0487, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0960, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8397, grad_fn=<DivBackward0>)\n",
      "tensor(1.0465, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0931, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8393, grad_fn=<DivBackward0>)\n",
      "tensor(1.0454, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0852, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8386, grad_fn=<DivBackward0>)\n",
      "tensor(1.0453, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0752, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8380, grad_fn=<DivBackward0>)\n",
      "tensor(1.0465, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0659, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8376, grad_fn=<DivBackward0>)\n",
      "tensor(1.0487, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0585, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8372, grad_fn=<DivBackward0>)\n",
      "tensor(1.0504, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0533, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8369, grad_fn=<DivBackward0>)\n",
      "tensor(1.0506, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0496, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8365, grad_fn=<DivBackward0>)\n",
      "tensor(1.0493, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0469, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8360, grad_fn=<DivBackward0>)\n",
      "tensor(1.0467, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0449, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8355, grad_fn=<DivBackward0>)\n",
      "tensor(1.0429, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0445, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8350, grad_fn=<DivBackward0>)\n",
      "tensor(1.0399, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0463, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8347, grad_fn=<DivBackward0>)\n",
      "tensor(1.0392, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0497, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8346, grad_fn=<DivBackward0>)\n",
      "tensor(1.0405, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0526, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8344, grad_fn=<DivBackward0>)\n",
      "tensor(1.0424, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0531, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8341, grad_fn=<DivBackward0>)\n",
      "tensor(1.0433, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0506, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8335, grad_fn=<DivBackward0>)\n",
      "tensor(1.0431, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0474, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8330, grad_fn=<DivBackward0>)\n",
      "tensor(1.0437, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0453, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8326, grad_fn=<DivBackward0>)\n",
      "tensor(1.0441, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0447, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8321, grad_fn=<DivBackward0>)\n",
      "tensor(1.0431, grad_fn=<SqrtBackward0>)\n",
      "tensor(1.0467, grad_fn=<SqrtBackward0>)\n",
      "##############\n",
      "tensor(2.8316, grad_fn=<DivBackward0>)\n",
      "tensor(1.0409, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m##############\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m train(model, train_adj_matr, num_users, num_items, optim)\n\u001b[0;32m----> 7\u001b[0m m_hat \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_adj_matr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_users\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[18], line 48\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, adj_matrix, num_playlists, num_songs)\u001b[0m\n\u001b[1;32m     45\u001b[0m m_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([(r\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mout \u001b[38;5;28;01mfor\u001b[39;00m r, out \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(output)], \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     46\u001b[0m m_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(m_hat, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrmse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m_hat\n",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m, in \u001b[0;36mrmse\u001b[0;34m(logits, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrmse\u001b[39m(logits, labels):\n\u001b[0;32m----> 2\u001b[0m     omg \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m      3\u001b[0m     len_omg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(torch\u001b[38;5;241m.\u001b[39mnonzero(omg))\n\u001b[1;32m      5\u001b[0m     pred_y \u001b[38;5;241m=\u001b[39m logits\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = GAE(num_users, num_items, train_adj_matr.shape[0], 10, 5)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "for epoch in tqdm(range(100)):\n",
    "    print('##############')\n",
    "    train(model, train_adj_matr, num_users, num_items, optim)\n",
    "    m_hat = evaluate(model, val_adj_matr, num_users, num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "76aee768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1, 1682])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.sort(\n",
       "values=tensor([[1.5464, 1.6289, 1.6351,  ..., 2.4633, 2.4648, 2.4711]],\n",
       "       grad_fn=<SortBackward0>),\n",
       "indices=tensor([[1672, 1507, 1082,  ..., 1670, 1433, 1373]]))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(10).sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b73994",
   "metadata": {},
   "source": [
    "#### Поэксперементируем теперь с музыкальным рекоммендательным датасетом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0a9246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# из https://github.com/fmonti/mgcnn\n",
    "def load_matlab_file(path_file, name_field):\n",
    "    \"\"\"\n",
    "    load '.mat' files\n",
    "    inputs:\n",
    "        path_file, string containing the file path\n",
    "        name_field, string containig the field name (default='shape')\n",
    "    warning:\n",
    "        '.mat' files should be saved in the '-v7.3' format\n",
    "    \"\"\"\n",
    "    db = h5py.File(path_file, 'r')\n",
    "    ds = db[name_field]\n",
    "    try:\n",
    "        if 'ir' in ds.keys():\n",
    "            data = np.asarray(ds['data'])\n",
    "            ir   = np.asarray(ds['ir'])\n",
    "            jc   = np.asarray(ds['jc'])\n",
    "            out  = sp.csc_matrix((data, ir, jc)).astype(np.float32)\n",
    "    except AttributeError:\n",
    "        # Transpose in case is a dense matrix because of the row- vs column- major ordering between python and matlab\n",
    "        out = np.asarray(ds).astype(np.float32).T\n",
    "\n",
    "    db.close()\n",
    "\n",
    "    return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
